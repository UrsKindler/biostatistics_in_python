# Cross-Validation

### Overview
- **Purpose**: Assess model performance and generalization to unseen data
- **Use Case**: Model evaluation, hyperparameter tuning, prevent overfitting
- **Prerequisites**: Labeled dataset with sufficient samples
- **Data Types**: Any data suitable for supervised learning

### When to Use
#### Decision Criteria
- **Use always**: Before deploying any machine learning model
- **Essential when**: Limited data, need unbiased performance estimate
- **Critical for**: Comparing multiple models, hyperparameter tuning
- **Choose method**: Based on data size and computational constraints

#### Data Type Requirements
- **Classification**: Labeled categorical outcomes
- **Regression**: Continuous numeric targets
- **Sample Size**: Minimum 30 samples per class for stratified CV
- **Not Suitable For**: Time series (use TimeSeriesSplit), very small datasets (<20 samples)

### R vs Python

| Aspect | R | Python |
|--------|---|--------|
| Package | `caret`, `mlr3` | `sklearn.model_selection` |
| K-Fold CV | `trainControl(method="cv", number=5)` | `KFold(n_splits=5)` |
| Stratified CV | `createFolds(stratified=TRUE)` | `StratifiedKFold()` |
| LOO CV | `trainControl(method="LOOCV")` | `LeaveOneOut()` |
| Time Series CV | `createTimeSlices()` | `TimeSeriesSplit()` |
| Cross-validate | `train(...)` | `cross_val_score()` |

### Quick Start Code

**R Example:**
```r
Load required library
library(caret)

Define cross-validation
train_control <- trainControl(method = "cv", number = 5)

Train model with CV
model <- train(y ~ ., data = train_data,
method = "rf",
trControl = train_control)

View results
print(model$results)
```

**Python Example:**
```python
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier

Prepare data
X = df.drop('target', axis=1)
y = df['target']

K-Fold Cross-Validation (regression or balanced classification)
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
model = RandomForestClassifier(random_state=42)
cv_scores = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')

print(f"CV Scores: {cv_scores}")
print(f"Mean Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})")

Stratified K-Fold (for imbalanced classification)
stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
strat_scores = cross_val_score(model, X, y, cv=stratified_kfold, scoring='accuracy')
print(f"Stratified CV Mean: {strat_scores.mean():.3f}")
```
